# -*- coding: utf-8 -*-
"""Bigrams of brown corpus

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CuQq1Tso2-lY8paMycBAfFVL4brqdK3u
"""

import nltk
nltk.download('punkt')
# nltk.download("averaged_perceptron_tagger')
from nltk import word_tokenize 
from nltk.util import ngrams
import nltk
nltk.download('averaged_perceptron_tagger')
f = open('/content/brown.csv')
raw = f.read()
 
tokens = nltk.word_tokenize(raw)
 
#Create your bigrams
bgs = nltk.bigrams(tokens)
 
 
#compute frequency distribution for all the bigrams in the text
fdist = nltk.FreqDist(bgs)
for k,v in fdist.items():
    print (k,v)
    print(nltk.pos_tag(bgs))

